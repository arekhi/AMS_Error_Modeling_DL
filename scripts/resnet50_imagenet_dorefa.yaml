quantizers:
  dorefa_quantizer:
    class: DorefaQuantizer
    bits_activations: 4
    bits_weights: 6
#    bits_overrides:
#    # Don't quantize first and last layer
#      conv1:
#        wts: null
#        acts: null
#      relu:
#        wts: null
#        acts: null
#      'layer4\.2\.relu':
#        wts: null
#        acts: null
#     fc:
#        wts: null
#        acts: null
#
#lr_schedulers:
#  training_lr:
#    class: MultiStepLR
#    milestones: [30, 60, 90, 100]
#    gamma: 0.1

policies:
    - quantizer:
        instance_name: dorefa_quantizer
      starting_epoch: 0
      ending_epoch: 200
      frequency: 1

#    - lr_scheduler:
#        instance_name: training_lr
#      starting_epoch: 0
#      ending_epoch: 200
#      frequency: 1
